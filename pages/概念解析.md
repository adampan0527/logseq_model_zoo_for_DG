# model zoo
模型库，顾名思义是一个预训练模型的集合，其中包含了诸多预训练模型
- # pretraining model
  
  预训练模型，指在大规模数据上进行了先前的训练的深度学习模型，包含了该领域内的通用特征，其存在的意义是能够帮助特定的下游任务模型更快地收敛，并提高其准确率，因此预训练模型更看重模型的泛化性能，而不是在某一特定任务上的准确率
- # domain generalization
  
  领域泛化，是指机器学习领域的一个任务，其目标是使模型在未见过的领域中表现良好
- # OoD
- Out-of-Distribution，分布外，指其他领域
- # IID
- Independent and Identically Distributed，独立同分布，在机器学习中，通常假设数据是 i.i.d，这意味着生成过程没有任何关于过去样本的记忆来生成新样本
- # SOTA
- 指领域中最好的XX，如SOTA model，指在该项研究任务中，对比该领域的其他模型，这个是目前最好/最先进的模型；SOTA Result，指在该领域的研究任务中，此论文的结果对比已经存在的模型及实现结果，此论文的模型具有最好的性能/结果
- # 疑问
- 1. domain generalization是一个任务，按理来说应该由一个模型来解决，如提高某一模型的泛化性能，而model zoo是一系列预训练模型的集合，要解决这个问题也该由其中的模型解决，但这又细化到了模型层面，并不需要model zoo的介入
  2. 借由疑问1引出：既然model zoo可以被应用在domain generalization这个任务上，意味着将多个预训练模型组成集合这个操作是有意义的，既然如此，那model zoo究竟是如何发挥出其作用的？如果不是像数组那样的调用其中的第i个元素（模型），那多个预训练模型怎么同时应用在一个任务中？
- # 可能有用的信息
- ## 数据集
- 以下数据集皆包含多个域
- PACS
  logseq.order-list-type:: number
- VLCS
  logseq.order-list-type:: number
- Office-Home
  logseq.order-list-type:: number
- TerraInc.
  logseq.order-list-type:: number
- DomainNet
  logseq.order-list-type:: number